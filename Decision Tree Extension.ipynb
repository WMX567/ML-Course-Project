{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Implementation with Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, nbins, data_range):\n",
    "        # Decision tree state here\n",
    "        # Feel free to add methods\n",
    "        self.bin_size = nbins\n",
    "        self.range = data_range\n",
    "\n",
    "    def preprocess(self, data):\n",
    "        # Our dataset only has continuous data\n",
    "        norm_data = np.clip((data - self.range[0]) / (self.range[1] - self.range[0]), 0, 1)\n",
    "        categorical_data = np.floor(self.bin_size * norm_data).astype(int)\n",
    "        return categorical_data\n",
    "\n",
    "    def train(self, X, y):\n",
    "        # training logic here\n",
    "        # input is array of features and labels\n",
    "        categorical_data = self.preprocess(X)\n",
    "        feature_names = []\n",
    "        for i in range(categorical_data.shape[1]):\n",
    "            feature_names.append(i)\n",
    "        X = list(categorical_data)\n",
    "        y = list(y)\n",
    "        self.tree = self.build_tree(X, y, [],feature_names)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Run model here\n",
    "        # Return array of predictions where there is one prediction for each set of features\n",
    "        categorical_data = self.preprocess(X)\n",
    "        predict_results = []\n",
    "        for x in categorical_data:\n",
    "            label = self.get_label(self.tree, x)\n",
    "            predict_results.append(label)\n",
    "        result = np.array(predict_results)\n",
    "        return result\n",
    "\n",
    "    def gini(self, labels):\n",
    "        class_count = {}\n",
    "        for label in labels:\n",
    "            if label not in class_count.keys():\n",
    "                class_count[label] = 1\n",
    "            else:\n",
    "                class_count[label] += 1\n",
    "        giniValue = 0\n",
    "        for label in class_count.keys():\n",
    "            prob = class_count[label] * 1.0 / len(labels)\n",
    "            giniValue += prob * prob\n",
    "        return 1 - giniValue\n",
    "\n",
    "    def get_attribute_label(self, feature_column, attribute, labels):\n",
    "        attri_labels = []\n",
    "        for i in range(len(labels)):\n",
    "            if feature_column[i] == attribute:\n",
    "                attri_labels.append(labels[i])\n",
    "        return attri_labels\n",
    "\n",
    "    def get_attribute_rows(self, feature_column, feature_selected, attribute, features):\n",
    "        new_features = []\n",
    "        for i in range(len(features)):\n",
    "            if feature_column[i] == attribute:\n",
    "                new_features.append(features[i])\n",
    "        if new_features != []:\n",
    "            new_features = np.delete(new_features, feature_selected, 1)\n",
    "        return new_features\n",
    "\n",
    "    def get_gini(self, feature_column, labels):\n",
    "        attributes = set(feature_column)\n",
    "        feature_gini= 0\n",
    "        for attribute in attributes:\n",
    "            attri_labels = self.get_attribute_label(feature_column, attribute, labels)\n",
    "            attri_count = feature_column.count(attribute)\n",
    "            feature_gini += attri_count/len(feature_column) * self.gini(attri_labels)\n",
    "        return feature_gini\n",
    "\n",
    "    def get_majority(self, labels):\n",
    "        class_count = {}\n",
    "        for label in labels:\n",
    "            if label not in class_count.keys():\n",
    "                class_count[label] = 1\n",
    "            else:\n",
    "                class_count[label] += 1\n",
    "        mostVote = -1000\n",
    "        labelSelected = -1\n",
    "        for label in class_count.keys():\n",
    "            if class_count[label] > mostVote:\n",
    "                mostVote = class_count[label]\n",
    "                labelSelected = label\n",
    "        return labelSelected\n",
    "\n",
    "    def is_labels_all_same(self, labels):\n",
    "        counter = labels.count(labels[0])\n",
    "        if counter == len(labels):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def is_row_all_same(self, X):\n",
    "        return np.equal(X[0], X).all()\n",
    "\n",
    "    def build_tree(self, X, y, parent_y, feature_names):\n",
    "        if len(y) == 0:\n",
    "            return self.get_majority(parent_y)\n",
    "\n",
    "        if self.is_labels_all_same(y):\n",
    "            return y[0]\n",
    "\n",
    "        if len(feature_names) == 1 or self.is_row_all_same(X):\n",
    "            return self.get_majority(y)\n",
    "\n",
    "        min_gini = 1000\n",
    "        selected = -1\n",
    "        for i in range(len(feature_names)):\n",
    "            feature_column = [x[i] for x in X]\n",
    "            gini = self.get_gini(feature_column, y)\n",
    "            if gini < min_gini:\n",
    "                min_gini = gini\n",
    "                selected = i\n",
    "\n",
    "        best_feature = feature_names[selected]\n",
    "        feature_column = [x[selected] for x in X]\n",
    "        feature_names.remove(feature_names[selected])\n",
    "\n",
    "        tree = {best_feature: {}}\n",
    "        attributes = set(feature_column)\n",
    "\n",
    "        for attribute in attributes:\n",
    "            new_X = self.get_attribute_rows(feature_column, selected, attribute, X)\n",
    "            new_y = self.get_attribute_label(feature_column, attribute, y)\n",
    "            sub_feature_names = feature_names[:]\n",
    "            tree[best_feature][attribute] = self.build_tree(new_X, new_y, y, sub_feature_names)\n",
    "        return tree\n",
    "\n",
    "    def get_label(self, tree, x):\n",
    "        key_list = list(tree.keys())\n",
    "        feature = key_list[0]\n",
    "        predict = -1000\n",
    "        for key in tree[feature].keys():\n",
    "            if x[feature] == key:\n",
    "                if type(tree[feature][key]).__name__ == 'dict':\n",
    "                    predict = self.get_label(tree[feature][key], x)\n",
    "                else:\n",
    "                    predict = tree[feature][key]\n",
    "        return predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, y_train, X_test, y_test, num_bin, num_tree):\n",
    "    num_feature = math.floor(2/3*len(X_train[0]))\n",
    "    num_train = math.floor(2/3*len(X_train))\n",
    "    feature_names = []\n",
    "    train_used = []\n",
    "    for i in range(len(X_train[0])):\n",
    "        feature_names.append(i)\n",
    "\n",
    "    for i in range(len(X_train)):\n",
    "        train_used.append(i)\n",
    "\n",
    "    results = []\n",
    "    for i in range(num_tree):\n",
    "        random.shuffle(feature_names)\n",
    "        random.shuffle(train_used)\n",
    "        feature_choose = feature_names[:num_feature]\n",
    "        train_examples = train_used[:num_train]\n",
    "        new_X_train = X_train[:, feature_choose]\n",
    "        new_X_train = new_X_train[train_examples, :]\n",
    "        new_y_train = y_train[train_examples]\n",
    "        data_range = (new_X_train.min(0), new_X_train.max(0))\n",
    "        tree = DecisionTree(num_bin, data_range)\n",
    "        tree.train(new_X_train, new_y_train)\n",
    "        new_X_test = X_test[:, feature_choose]\n",
    "        predictions = tree.predict(new_X_test)\n",
    "        results.append(predictions)\n",
    "    \n",
    "    results = np.array(results)\n",
    "    solutions = []\n",
    "    for i in range(len(results[0])):\n",
    "        solution = get_majority(results[:, i])\n",
    "        solutions.append(solution)\n",
    "\n",
    "    solutions = np.array(solutions)\n",
    "    y_labels = np.array(y_test)\n",
    "    print(\"Random Forest Accuracy: \", evaluate(solutions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(solutions, real):\n",
    "    if(solutions.shape != real.shape):\n",
    "        raise ValueError(\"Output is wrong shape.\")\n",
    "    predictions = np.array(solutions)\n",
    "    labels = np.array(real)\n",
    "    return (predictions == labels).sum() / float(labels.size)\n",
    "\n",
    "def get_majority(labels):\n",
    "    class_count = {}\n",
    "    for label in labels:\n",
    "        if label not in class_count.keys():\n",
    "            class_count[label] = 1\n",
    "        else:\n",
    "            class_count[label] += 1\n",
    "    mostVote = -1000\n",
    "    labelSelected = -1\n",
    "    for label in class_count.keys():\n",
    "        if class_count[label] > mostVote:\n",
    "            mostVote = class_count[label]\n",
    "            labelSelected = label\n",
    "    return labelSelected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on Handwritten digit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1078, 64)\n",
      "(1078,)\n"
     ]
    }
   ],
   "source": [
    "digits=load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Compare effects between single decision tree and random forest on sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Single Tree Accuracy:  0.8442280945757997\n",
      "sklearn Random Forest Accuracy:  0.9541029207232267\n"
     ]
    }
   ],
   "source": [
    "single_tree_sklearn = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "single_tree_sklearn.fit(X_train, y_train)\n",
    "sklearn_tree_predictions = single_tree_sklearn.predict(X_test)\n",
    "print(\"sklearn Single Tree Accuracy: \", evaluate(sklearn_tree_predictions, y_test))\n",
    "\n",
    "forest_sklearn = RandomForestClassifier(n_estimators=20)\n",
    "forest_sklearn.fit(X_train, y_train)\n",
    "sklearn_forest_predictions = forest_sklearn.predict(X_test)\n",
    "print(\"sklearn Random Forest Accuracy: \", evaluate(sklearn_forest_predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Compare effects between single decision tree and random forest on our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Tree Accuracy:  0.6898470097357441\n",
      "Random Forest Accuracy:  0.885952712100139\n"
     ]
    }
   ],
   "source": [
    "data_range = (X_train.min(0), X_train.max(0))\n",
    "single_tree = DecisionTree(3, data_range)\n",
    "single_tree.train(X_train, y_train)\n",
    "predictions = single_tree.predict(X_test)\n",
    "print(\"Single Tree Accuracy: \", evaluate(predictions, y_test))\n",
    "\n",
    "random_forest(X_train, y_train, X_test, y_test, 3, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on Spambase data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"spambase.csv\", delimiter=',')\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "X_train = data.loc[:3000, \"word1\":\"word57\"].values\n",
    "y_train = data.loc[:3000, \"labels\"].values\n",
    "X_test = data.loc[3001:, \"word1\":\"word57\"].values\n",
    "y_test = data.loc[3001:, \"labels\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Tree Accuracy:  0.766875\n",
      "Random Forest Accuracy:  0.861875\n"
     ]
    }
   ],
   "source": [
    "data_range = (X_train.min(0), X_train.max(0))\n",
    "single_tree = DecisionTree(10, data_range)\n",
    "single_tree.train(X_train, y_train)\n",
    "predictions = single_tree.predict(X_test)\n",
    "print(\"Single Tree Accuracy: \", evaluate(predictions, y_test))\n",
    "\n",
    "random_forest(X_train, y_train, X_test, y_test, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
