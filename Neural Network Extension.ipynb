{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score \n",
    "import numpy as np\n",
    "import numpy.random as r\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The activation function and its derivative\n",
    "\n",
    "We will use the sigmoid activation function:  $f(z)=\\frac{1}{1+e^{-z}}$\n",
    "\n",
    "The deriviative of the sigmoid function is: $f'(z) = f(z)(1-f(z))$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def f_deriv(z):\n",
    "    return f(z) * (1 - f(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and initialing W and b\n",
    "We want the weights in W to be different so that during back propagation the nodes on a level will have different gradients and thus have different update values.\n",
    "\n",
    "We want the  weights to be small values, since the sigmoid is almost \"flat\" for large inputs.\n",
    "\n",
    "Next is the code that assigns each weight a number uniformly drawn from $[0.0, 1.0)$.  The code assumes that the number of neurons in each level is in the python list *nn_structure*.\n",
    "\n",
    "In the code, the weights, $W^{(\\ell)}$ and $b^{(\\ell)}$ are held in a python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_and_init_weights(nn_structure):\n",
    "    W = {} #creating a dictionary i.e. a set of key: value pairs\n",
    "    b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        a = np.sqrt(6 / (nn_structure[l] + nn_structure[l-1]))\n",
    "        W[l] = 2*a* r.random_sample((nn_structure[l], nn_structure[l-1])) - a #Return “continuous uniform” random floats in the half-open interval [0.0, 1.0). \n",
    "        b[l] = 2*a* r.random_sample((nn_structure[l],)) - a\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing $\\triangledown W$ and $\\triangledown b$\n",
    "Creating $\\triangledown W^{(\\ell)}$ and $\\triangledown b^{(\\ell)}$ to have the same size as $W^{(\\ell)}$ and $b^{(\\ell)}$, and setting $\\triangledown W^{(\\ell)}$, and  $\\triangledown b^{(\\ell)}$ to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_tri_values(nn_structure):\n",
    "    tri_W = {}\n",
    "    tri_b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        tri_W[l] = np.zeros((nn_structure[l], nn_structure[l-1]))\n",
    "        tri_b[l] = np.zeros((nn_structure[l],))\n",
    "    return tri_W, tri_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed forward\n",
    "Perform a forward pass throught the network.  The function returns the values of $a$ and $z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(x, W, b):\n",
    "    a = {1: x} # create a dictionary for holding the a values for all levels\n",
    "    z = { } # create a dictionary for holding the z values for all the layers\n",
    "    for l in range(1, len(W) + 1): # for each layer\n",
    "        node_in = a[l]\n",
    "        z[l+1] = W[l].dot(node_in) + b[l]  # z^(l+1) = W^(l)*a^(l) + b^(l)\n",
    "        a[l+1] = f(z[l+1]) # a^(l+1) = f(z^(l+1))\n",
    "    return a, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute $\\delta$\n",
    "The code below compute $\\delta^{(s_l)}$ in a function called \"calculate_out_layer_delta\",  and  computes $\\delta^{(\\ell)}$ for the hidden layers in the function called \"calculate_hidden_delta\".  \n",
    "\n",
    "If we wanted to have a different cost function, we would change the \"calculate_out_layer_delta\" function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_out_layer_delta(y, a_out, z_out):\n",
    "    # delta^(nl) = -(y_i - a_i^(nl)) * f'(z_i^(nl))\n",
    "    return -(y-a_out) * f_deriv(z_out)\n",
    "\n",
    "\n",
    "def calculate_hidden_delta(delta_plus_1, w_l, z_l):\n",
    "    # delta^(l) = (transpose(W^(l)) * delta^(l+1)) * f'(z^(l))\n",
    "    return np.dot(np.transpose(w_l), delta_plus_1) * f_deriv(z_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize hw and hb for Ada Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_h_w_b_values(nn_structure):\n",
    "    h_w = {}\n",
    "    h_b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        h_w[l] = np.zeros((nn_structure[l], nn_structure[l-1]))\n",
    "        h_b[l] = np.zeros((nn_structure[l],))\n",
    "    return h_w, h_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Back Propagation Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(nn_structure, X, y, iter_num, alpha, lamb):\n",
    "    W, b = setup_and_init_weights(nn_structure)\n",
    "    cnt = 0\n",
    "    N = len(y)\n",
    "    avg_cost_func = []\n",
    "    print('Starting gradient descent for {} iterations'.format(iter_num))\n",
    "    h_w, h_b = init_h_w_b_values(nn_structure)\n",
    "    while cnt < iter_num:\n",
    "        if cnt%1000 == 0:\n",
    "            print('Iteration {} of {}'.format(cnt, iter_num))\n",
    "        tri_W, tri_b = init_tri_values(nn_structure)\n",
    "        avg_cost = 0\n",
    "        for i in range(N):\n",
    "            delta = {}\n",
    "            # perform the feed forward pass and return the stored a and z values, to be used in the\n",
    "            # gradient descent step\n",
    "            a, z = feed_forward(X[i, :], W, b)\n",
    "            # loop from nl-1 to 1 backpropagating the errors\n",
    "            for l in range(len(nn_structure), 0, -1):\n",
    "                if l == len(nn_structure):\n",
    "                    delta[l] = calculate_out_layer_delta(y[i,:], a[l], z[l])\n",
    "                    avg_cost += np.linalg.norm((y[i,:]-a[l]))\n",
    "                else:\n",
    "                    if l > 1:\n",
    "                        delta[l] = calculate_hidden_delta(delta[l+1], W[l], z[l])\n",
    "                    # triW^(l) = triW^(l) + delta^(l+1) * transpose(a^(l))\n",
    "                    tri_W[l] += np.dot(delta[l+1][:,np.newaxis], np.transpose(a[l][:,np.newaxis]))# np.newaxis increase the number of dimensions\n",
    "                    # trib^(l) = trib^(l) + delta^(l+1)\n",
    "                    tri_b[l] += delta[l+1]\n",
    "        # perform the gradient descent step for the weights in each layer\n",
    "        for l in range(len(nn_structure) - 1, 0, -1):\n",
    "            h_w[l] += tri_W[l] * tri_W[l]\n",
    "            h_b[l] += tri_b[l] * tri_b[l]\n",
    "            \n",
    "            W[l] += -alpha * (tri_W[l] + lamb/2*W[l])/(np.sqrt(h_w[l]) + 1e-7)\n",
    "            b[l] += -alpha * (tri_b[l]/(np.sqrt(h_b[l]) + 1e-7))\n",
    "        # complete the average cost calculation\n",
    "        # Remain the \n",
    "        avg_cost = 1.0/N * avg_cost \n",
    "        avg_cost_func.append(avg_cost)\n",
    "        cnt += 1\n",
    "    return W, b, avg_cost_func\n",
    "\n",
    "\n",
    "def predict_y(W, b, X, n_layers):\n",
    "    N = X.shape[0]\n",
    "    y = np.zeros((N,))\n",
    "    for i in range(N):\n",
    "        a, z = feed_forward(X[i, :], W, b)\n",
    "        y[i] = np.argmax(a[n_layers])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding\n",
    "Our target is an integer in the range [0,..,9], so we will have 10 output neuron's in our network.  \n",
    "\n",
    "-  If  $y=0$, we want the output neurons to have the values $(1,0,0,0,0,0,0,0,0,0)$\n",
    "\n",
    "-  If  $y=1$ we want the output neurons to have the values $(0,1,0,0,0,0,0,0,0,0)$\n",
    "-  etc\n",
    "\n",
    "Thus we need to change our target so it is the same as our hoped for output of the neural network.  \n",
    "-  If $y=0$ we change it into the vector $(1,0,0,0,0,0,0,0,0,0)$. \n",
    "-  If $y=1$ we change it into the vector $(0,1,0,0,0,0,0,0,0,0)$\n",
    "-  etc\n",
    "\n",
    "See page 29 from the website listed above\n",
    "\n",
    "The code to covert the target vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_to_vect(y, num_class):\n",
    "    y_vect = np.zeros((len(y), num_class))\n",
    "    for i in range(len(y)):\n",
    "        y_vect[i, y[i]] = 1\n",
    "    return y_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on Handwritten Digits data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent for 3000 iterations\n",
      "Iteration 0 of 3000\n",
      "Iteration 1000 of 3000\n",
      "Iteration 2000 of 3000\n"
     ]
    }
   ],
   "source": [
    "digits=load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "X_scale = StandardScaler()\n",
    "X = X_scale.fit_transform(digits.data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "y_v_train = convert_y_to_vect(y_train, 10)\n",
    "y_v_test = convert_y_to_vect(y_test, 10)\n",
    "\n",
    "\n",
    "nn_structure = [64, 30, 10]\n",
    "    \n",
    "# train the NN\n",
    "alpha = 0.25\n",
    "lamb = 0.01\n",
    "W, b, avg_cost_func = train_nn(nn_structure, X_train, y_v_train, 3000, alpha, lamb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the learning curve for handwritten digits data for Adagrad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the avg_cost_func\n",
    "plt.plot(avg_cost_func)\n",
    "plt.ylabel('Average J')\n",
    "plt.xlabel('Iteration number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction accuracy for handwritten digits data for Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy is 97.63560500695411%\n"
     ]
    }
   ],
   "source": [
    "# get the prediction accuracy and print\n",
    "y_pred = predict_y(W, b, X_test, 3)\n",
    "print('Prediction accuracy is {}%'.format(accuracy_score(y_test, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on Iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent for 3000 iterations\n",
      "Iteration 0 of 3000\n",
      "Iteration 1000 of 3000\n",
      "Iteration 2000 of 3000\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_scale = StandardScaler()\n",
    "X = X_scale.fit_transform(iris.data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "y_v_train = convert_y_to_vect(y_train, 3)\n",
    "y_v_test = convert_y_to_vect(y_test, 3)\n",
    "\n",
    "nn_structure = [4, 30, 3]\n",
    "\n",
    "alpha = 0.25\n",
    "lamb = 0.01\n",
    "W, b, avg_cost_func = train_nn(nn_structure, X_train, y_v_train, 3000, alpha, lamb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the learning curve for iris data for Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the avg_cost_func\n",
    "plt.plot(avg_cost_func)\n",
    "plt.ylabel('Average J')\n",
    "plt.xlabel('Iteration number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction accuracy for iris data for Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy is 96.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "# get the prediction accuracy and print\n",
    "y_pred = predict_y(W, b, X_test, 3)\n",
    "print('Prediction accuracy is {}%'.format(accuracy_score(y_test, y_pred) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
